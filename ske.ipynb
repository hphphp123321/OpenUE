{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文三元组联合抽取\n",
    "\n",
    "## 介绍\n",
    "\n",
    "在这个notebook中我们将使用openue库代码来训练我们自己的三元组联合抽取，使用的基础模型是`bert-base-chinese`，训练分为两步，首先训练关系分类模型，其次训练实体抽取模型。之后联合验证。\n",
    "\n",
    "## 数据集\n",
    "\n",
    "在这个数据集中，使用ske数据集，具体例子如下。我们使用代码来读取`train.json`来分析一下数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/ske/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38485/2770818538.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../dataset/ske/train.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/ske/train.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../dataset/ske/train.json\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        example = json.loads(line)\n",
    "        break\n",
    "for k, v in example.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练\n",
    "\n",
    "## `seq model`关系分类模型\n",
    "\n",
    "如我们的模型图所示，我们需要先训练一个关系分类模型，识别出句子中实体的属性。也就是模型图中下方位置的关系类型识别模块，用来识别出句子中存在的关系。\n",
    "\n",
    "我们训练和验证模型使用的都是同一份代码，区别仅为`config`的设置不同，config具体的文件目录在`./config`下。\n",
    "<div  align=\"center\">\n",
    "    <img src=\"./imgs/architecture.png\" width = \"600\" height = \"400\" alt=\"图片名称\" align=center />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import openue.lit_models as lit_models\n",
    "import yaml\n",
    "import time\n",
    "from transformers import AutoConfig\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置一些参数和动态调用包\n",
    "def _import_class(module_and_class_name: str) -> type:\n",
    "    module_name, class_name = module_and_class_name.rsplit(\".\", 1)\n",
    "    module = importlib.import_module(module_name)\n",
    "    class_ = getattr(module, class_name)\n",
    "\t\n",
    "    return class_\n",
    "\n",
    "\n",
    "def _setup_parser():\n",
    "    \"\"\"Set up Python's ArgumentParser with data, model, trainer, and other arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(add_help=False)\n",
    "\n",
    "    # Add Trainer specific arguments, such as --max_epochs, --gpus, --precision\n",
    "    # trainer_parser = pl.Trainer.add_argparse_args(parser)\n",
    "    # trainer_parser._action_groups[1].title = \"Trainer Args\"  # pylint: disable=protected-access\n",
    "    # parser = argparse.ArgumentParser(add_help=False, parents=[trainer_parser])\n",
    "\n",
    "    # Basic arguments\n",
    "    parser.add_argument(\"--wandb\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--litmodel_class\", type=str, default=\"SEQLitModel\")\n",
    "    parser.add_argument(\"--data_class\", type=str, default=\"REDataset\")\n",
    "    parser.add_argument(\"--model_class\", type=str, default=\"BertForRelationClassification\")\n",
    "    parser.add_argument(\"--load_checkpoint\", type=str, default=None)\n",
    "\n",
    "    # Get the data and model classes, so that we can add their specific arguments\n",
    "    temp_args, _ = parser.parse_known_args()\n",
    "    data_class = _import_class(f\"openue.data.{temp_args.data_class}\")\n",
    "    model_class = _import_class(f\"openue.models.{temp_args.model_class}\")\n",
    "\n",
    "    # Get data, model, and LitModel specific arguments\n",
    "    data_group = parser.add_argument_group(\"Data Args\")\n",
    "    data_class.add_to_argparse(data_group)\n",
    "\n",
    "    model_group = parser.add_argument_group(\"Model Args\")\n",
    "    model_class.add_to_argparse(model_group)\n",
    "\n",
    "    lit_model_group = parser.add_argument_group(\"LitModel Args\")\n",
    "    lit_models.BaseLitModel.add_to_argparse(lit_model_group)\n",
    "\n",
    "    parser.add_argument(\"--help\", \"-h\", action=\"help\")\n",
    "    return parser\n",
    "\n",
    "def _save_model(litmodel, tokenizer, path):\n",
    "    os.system(f\"mkdir -p {path}\")\n",
    "    litmodel.model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-ab359acddc76>:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  opt = yaml.load(open(path))\n",
      "12/26/2021 18:45:49 - INFO - openue.data.data_module -   add total special tokens: 50 \n",
      " ['[relation0]', '[relation1]', '[relation2]', '[relation3]', '[relation4]', '[relation5]', '[relation6]', '[relation7]', '[relation8]', '[relation9]', '[relation10]', '[relation11]', '[relation12]', '[relation13]', '[relation14]', '[relation15]', '[relation16]', '[relation17]', '[relation18]', '[relation19]', '[relation20]', '[relation21]', '[relation22]', '[relation23]', '[relation24]', '[relation25]', '[relation26]', '[relation27]', '[relation28]', '[relation29]', '[relation30]', '[relation31]', '[relation32]', '[relation33]', '[relation34]', '[relation35]', '[relation36]', '[relation37]', '[relation38]', '[relation39]', '[relation40]', '[relation41]', '[relation42]', '[relation43]', '[relation44]', '[relation45]', '[relation46]', '[relation47]', '[relation48]', '[relation49]']\n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForRelationClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForRelationClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForRelationClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForRelationClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['relation_classification.weight', 'relation_classification.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "12/26/2021 18:46:03 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_train_BertTokenizerFast_seq\n",
      "12/26/2021 18:46:10 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_dev_BertTokenizerFast_seq\n",
      "12/26/2021 18:46:11 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_test_BertTokenizerFast_seq\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                          | Params\n",
      "----------------------------------------------------------\n",
      "0 | loss_fn | BCEWithLogitsLoss             | 0     \n",
      "1 | model   | BertForRelationClassification | 102 M \n",
      "----------------------------------------------------------\n",
      "102 M     Trainable params\n",
      "0         Non-trainable params\n",
      "102 M     Total params\n",
      "409.378   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d571aae7fbd4e6a9f2176227bdc66b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "110c381a0815431a8833b21030ea2bd1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8e0796a7bf44787ac5628e9a980e22b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2021 19:04:04 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_train_BertTokenizerFast_seq\n",
      "12/26/2021 19:04:14 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_dev_BertTokenizerFast_seq\n",
      "12/26/2021 19:04:15 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_test_BertTokenizerFast_seq\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0732496c135e4eee8d950ef9a4e1c51a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test/f1': 0.8977343506652946}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "parser = _setup_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "path = \"./config/run_seq.yaml\"\n",
    "# 使用config.yaml 载入超参设置\n",
    "opt = yaml.load(open(path))\n",
    "args.__dict__.update(opt)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "data_class = _import_class(f\"openue.data.{args.data_class}\")\n",
    "model_class = _import_class(f\"openue.models.{args.model_class}\")\n",
    "litmodel_class = _import_class(f\"openue.lit_models.{args.litmodel_class}\")\n",
    "\n",
    "data = data_class(args)\n",
    "\n",
    "lit_model = litmodel_class(args=args, data_config=data.get_config())\n",
    "\n",
    "\n",
    "\n",
    "# logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "# if args.wandb:\n",
    "#     logger = pl.loggers.WandbLogger(project=\"openue demo\")\n",
    "#     logger.log_hyperparams(vars(args))\n",
    "\n",
    "early_callback = pl.callbacks.EarlyStopping(monitor=\"Eval/f1\", mode=\"max\", patience=5)\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"Eval/f1\", mode=\"max\",\n",
    "    filename='{epoch}-{Eval/f1:.2f}',\n",
    "    dirpath=\"output\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [early_callback, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, default_root_dir=\"training/logs\")\n",
    "\n",
    "trainer.fit(lit_model, datamodule=data)\n",
    "\n",
    "trainer.test(lit_model, datamodule=data)\n",
    "\n",
    "\n",
    "_save_model(litmodel=lit_model, tokenizer=data.tokenizer, path=\"seq_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实体识别模块\n",
    "\n",
    "在训练过程中，我们利用golden标签进行实体识别，即假设已经获得句子中存在的关系，之后利用这些关系来进行实体识别。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-90a04b961563>:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  opt = yaml.load(open(path))\n",
      "12/26/2021 19:12:18 - INFO - openue.data.data_module -   add total special tokens: 50 \n",
      " ['[relation0]', '[relation1]', '[relation2]', '[relation3]', '[relation4]', '[relation5]', '[relation6]', '[relation7]', '[relation8]', '[relation9]', '[relation10]', '[relation11]', '[relation12]', '[relation13]', '[relation14]', '[relation15]', '[relation16]', '[relation17]', '[relation18]', '[relation19]', '[relation20]', '[relation21]', '[relation22]', '[relation23]', '[relation24]', '[relation25]', '[relation26]', '[relation27]', '[relation28]', '[relation29]', '[relation30]', '[relation31]', '[relation32]', '[relation33]', '[relation34]', '[relation35]', '[relation36]', '[relation37]', '[relation38]', '[relation39]', '[relation40]', '[relation41]', '[relation42]', '[relation43]', '[relation44]', '[relation45]', '[relation46]', '[relation47]', '[relation48]', '[relation49]']\n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForNER: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForNER from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNER from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForNER were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['token_classification.weight', 'token_classification.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "12/26/2021 19:12:34 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_train_BertTokenizerFast_ner\n",
      "12/26/2021 19:12:48 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_dev_BertTokenizerFast_ner\n",
      "12/26/2021 19:12:48 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_test_BertTokenizerFast_ner\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss_fn | BCEWithLogitsLoss | 0     \n",
      "1 | model   | BertForNER        | 102 M \n",
      "----------------------------------------------\n",
      "102 M     Trainable params\n",
      "0         Non-trainable params\n",
      "102 M     Total params\n",
      "409.249   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c11d38a6158d4a79bb0fd3d950948e71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ddc623dba29455897dc74b5a7059fb2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2e58a52c3b14790b85ead690751257d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e55928c7080417da430da86c622e6c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcb9241bfe3d4c27a87ad200427be6ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71683fdd138448cfa4ac8555009e303f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60ca2030397442739ef07aa1b81b2081"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2021 20:55:59 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_train_BertTokenizerFast_ner\n",
      "12/26/2021 20:56:09 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_dev_BertTokenizerFast_ner\n",
      "12/26/2021 20:56:09 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske\\cached_test_BertTokenizerFast_ner\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38f4ccde716046cdb4de568529fa1b80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test/f1': 0.7944407968148107}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "parser = _setup_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "path = \"./config/run_ner.yaml\"\n",
    "# 使用config.yaml 载入超参设置\n",
    "opt = yaml.load(open(path))\n",
    "args.__dict__.update(opt)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "data_class = _import_class(f\"openue.data.{args.data_class}\")\n",
    "model_class = _import_class(f\"openue.models.{args.model_class}\")\n",
    "litmodel_class = _import_class(f\"openue.lit_models.{args.litmodel_class}\")\n",
    "\n",
    "data = data_class(args)\n",
    "\n",
    "lit_model = litmodel_class(args=args, data_config=data.get_config())\n",
    "\n",
    "\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "if args.wandb:\n",
    "    logger = pl.loggers.WandbLogger(project=\"openue demo\")\n",
    "    logger.log_hyperparams(vars(args))\n",
    "\n",
    "early_callback = pl.callbacks.EarlyStopping(monitor=\"Eval/f1\", mode=\"max\", patience=5)\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"Eval/f1\", mode=\"max\",\n",
    "    filename='{epoch}-{Eval/f1:.2f}',\n",
    "    dirpath=\"output\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [early_callback, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, logger=logger, default_root_dir=\"training/logs\")\n",
    "\n",
    "trainer.fit(lit_model, datamodule=data)\n",
    "\n",
    "trainer.test(lit_model, datamodule=data)\n",
    "_save_model(litmodel=lit_model, tokenizer=data.tokenizer, path=\"ner_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证\n",
    "\n",
    "由于我们使用pipeline模型，所以无法联合训练，需要分别训练后进行统一验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-4b102359eb37>:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  opt = yaml.load(open(path))\n",
      "12/26/2021 21:00:42 - INFO - openue.data.data_module -   add total special tokens: 50 \n",
      " ['[relation0]', '[relation1]', '[relation2]', '[relation3]', '[relation4]', '[relation5]', '[relation6]', '[relation7]', '[relation8]', '[relation9]', '[relation10]', '[relation11]', '[relation12]', '[relation13]', '[relation14]', '[relation15]', '[relation16]', '[relation17]', '[relation18]', '[relation19]', '[relation20]', '[relation21]', '[relation22]', '[relation23]', '[relation24]', '[relation25]', '[relation26]', '[relation27]', '[relation28]', '[relation29]', '[relation30]', '[relation31]', '[relation32]', '[relation33]', '[relation34]', '[relation35]', '[relation36]', '[relation37]', '[relation38]', '[relation39]', '[relation40]', '[relation41]', '[relation42]', '[relation43]', '[relation44]', '[relation45]', '[relation46]', '[relation47]', '[relation48]', '[relation49]']\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "12/26/2021 21:00:44 - INFO - openue.data.utils -   Loading example from dataset file at ./dataset/ske\n",
      "12/26/2021 21:00:51 - INFO - openue.data.utils -   Creating features from dataset file at ./dataset/ske\n",
      "12/26/2021 21:00:51 - INFO - openue.data.utils -   Writing example 0 of 173108\n",
      "12/26/2021 21:00:55 - INFO - openue.data.utils -   Writing example 10000 of 173108\n",
      "12/26/2021 21:00:59 - INFO - openue.data.utils -   Writing example 20000 of 173108\n",
      "12/26/2021 21:01:02 - INFO - openue.data.utils -   Writing example 30000 of 173108\n",
      "12/26/2021 21:01:05 - INFO - openue.data.utils -   Writing example 40000 of 173108\n",
      "12/26/2021 21:01:08 - INFO - openue.data.utils -   Writing example 50000 of 173108\n",
      "12/26/2021 21:01:12 - INFO - openue.data.utils -   Writing example 60000 of 173108\n",
      "12/26/2021 21:01:16 - INFO - openue.data.utils -   Writing example 70000 of 173108\n",
      "12/26/2021 21:01:19 - INFO - openue.data.utils -   Writing example 80000 of 173108\n",
      "12/26/2021 21:01:23 - INFO - openue.data.utils -   Writing example 90000 of 173108\n",
      "12/26/2021 21:01:26 - INFO - openue.data.utils -   Writing example 100000 of 173108\n",
      "12/26/2021 21:01:29 - INFO - openue.data.utils -   Writing example 110000 of 173108\n",
      "12/26/2021 21:01:33 - INFO - openue.data.utils -   Writing example 120000 of 173108\n",
      "12/26/2021 21:01:36 - INFO - openue.data.utils -   Writing example 130000 of 173108\n",
      "12/26/2021 21:01:41 - INFO - openue.data.utils -   Writing example 140000 of 173108\n",
      "12/26/2021 21:01:44 - INFO - openue.data.utils -   Writing example 150000 of 173108\n",
      "12/26/2021 21:01:47 - INFO - openue.data.utils -   Writing example 160000 of 173108\n",
      "12/26/2021 21:01:51 - INFO - openue.data.utils -   Writing example 170000 of 173108\n",
      "12/26/2021 21:01:52 - INFO - openue.data.utils -   InputExample(text_id=0, words='如何演好自己的角色，请读《演员自我修养》《喜剧之王》周星驰崛起于穷困潦倒之中的独门秘笈', triples=[['喜剧之王', '主演', '周星驰']])\n",
      "12/26/2021 21:01:52 - INFO - openue.data.utils -   InputFeatures_Interactive(input_ids=[101, 1963, 862, 4028, 1962, 5632, 2346, 4638, 6235, 5682, 8024, 6435, 6438, 517, 4028, 1447, 5632, 2769, 934, 1075, 518, 517, 1599, 1196, 722, 4374, 518, 1453, 3215, 7720, 2307, 6629, 754, 4956, 1737, 4057, 948, 722, 704, 4638, 4324, 7305, 4908, 5007, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], triples=[[22, 26, 27, 30, 5]])\n",
      "12/26/2021 21:01:52 - INFO - openue.data.utils -   Saving features into cached file ./dataset/ske\\cached_train_BertTokenizerFast_interactive\n",
      "12/26/2021 21:01:59 - INFO - openue.data.utils -   Loading example from dataset file at ./dataset/ske\n",
      "12/26/2021 21:01:59 - INFO - openue.data.utils -   Creating features from dataset file at ./dataset/ske\n",
      "12/26/2021 21:01:59 - INFO - openue.data.utils -   Writing example 0 of 10000\n",
      "12/26/2021 21:02:02 - INFO - openue.data.utils -   InputExample(text_id=0, words='查尔斯·阿兰基斯（Charles Aránguiz），1989年4月17日出生于智利圣地亚哥，智利职业足球运动员，司职中场，效力于德国足球甲级联赛勒沃库森足球俱乐部', triples=[['查尔斯·阿兰基斯', '出生地', '圣地亚哥'], ['查尔斯·阿兰基斯', '出生日期', '1989年4月17日']])\n",
      "12/26/2021 21:02:02 - INFO - openue.data.utils -   InputFeatures_Interactive(input_ids=[101, 3389, 2209, 3172, 185, 7350, 1065, 1825, 3172, 8020, 10403, 100, 8021, 8024, 8528, 2399, 125, 3299, 8126, 3189, 1139, 4495, 754, 3255, 1164, 1760, 1765, 762, 1520, 8024, 3255, 1164, 5466, 689, 6639, 4413, 6817, 1220, 1447, 8024, 1385, 5466, 704, 1767, 8024, 3126, 1213, 754, 2548, 1744, 6639, 4413, 4508, 5277, 5468, 6612, 1239, 3753, 2417, 3481, 6639, 4413, 936, 727, 6956, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], triples=[[1, 9, 25, 29, 14], [1, 9, 14, 20, 15]])\n",
      "12/26/2021 21:02:02 - INFO - openue.data.utils -   Saving features into cached file ./dataset/ske\\cached_dev_BertTokenizerFast_interactive\n",
      "12/26/2021 21:02:03 - INFO - openue.data.utils -   Loading example from dataset file at ./dataset/ske\n",
      "12/26/2021 21:02:03 - INFO - openue.data.utils -   Creating features from dataset file at ./dataset/ske\n",
      "12/26/2021 21:02:03 - INFO - openue.data.utils -   Writing example 0 of 11639\n",
      "12/26/2021 21:02:06 - INFO - openue.data.utils -   Writing example 10000 of 11639\n",
      "12/26/2021 21:02:07 - INFO - openue.data.utils -   InputExample(text_id=0, words='梅亭社区是广东省深圳市福田区梅林街道办事处所辖的一个居民小区，社区面积1.5平方公里，总人口18567人', triples=[['梅亭社区', '人口数量', '18567人'], ['梅亭社区', '面积', '1.5平方公里']])\n",
      "12/26/2021 21:02:07 - INFO - openue.data.utils -   InputFeatures_Interactive(input_ids=[101, 3449, 777, 4852, 1277, 3221, 2408, 691, 4689, 3918, 1766, 2356, 4886, 4506, 1277, 3449, 3360, 6125, 6887, 1215, 752, 1905, 2792, 6785, 4638, 671, 702, 2233, 3696, 2207, 1277, 8024, 4852, 1277, 7481, 4916, 122, 119, 126, 2398, 3175, 1062, 7027, 8024, 2600, 782, 1366, 9560, 9411, 782, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], triples=[[1, 5, 47, 50, 7], [1, 5, 36, 43, 48]])\n",
      "12/26/2021 21:02:07 - INFO - openue.data.utils -   Saving features into cached file ./dataset/ske\\cached_test_BertTokenizerFast_interactive\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39c96850f0fd406096a88f760ffe494f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test/f1': 0.7584634054483826}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'Test/f1': 0.7584634054483826}]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = _setup_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "path = \"./config/run_infer.yaml\"\n",
    "# 使用config.yaml 载入超参设置\n",
    "opt = yaml.load(open(path))\n",
    "args.__dict__.update(opt)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "data_class = _import_class(f\"openue.data.{args.data_class}\")\n",
    "model_class = _import_class(f\"openue.models.{args.model_class}\")\n",
    "litmodel_class = _import_class(f\"openue.lit_models.{args.litmodel_class}\")\n",
    "\n",
    "data = data_class(args)\n",
    "\n",
    "lit_model = litmodel_class(args=args, data_config=data.get_config())\n",
    "\n",
    "\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "if args.wandb:\n",
    "    logger = pl.loggers.WandbLogger(project=\"openue demo\")\n",
    "    logger.log_hyperparams(vars(args))\n",
    "\n",
    "early_callback = pl.callbacks.EarlyStopping(monitor=\"Eval/f1\", mode=\"max\", patience=5)\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"Eval/f1\", mode=\"max\",\n",
    "    filename='{epoch}-{Eval/f1:.2f}',\n",
    "    dirpath=\"output\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [early_callback, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, logger=logger, default_root_dir=\"training/logs\")\n",
    "\n",
    "if \"infer\" not in path :trainer.fit(lit_model, datamodule=data)\n",
    "\n",
    "trainer.test(lit_model, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ee29d4c65a463677a56f7e718e0fe6afedbb1a78c06a034d94d3fcc7a37838e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
